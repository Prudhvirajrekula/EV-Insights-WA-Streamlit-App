{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffe370d4",
   "metadata": {},
   "source": [
    "# üöó EV Insights: Trends & Predictions in Washington's Clean Vehicle Movement\n",
    "### Author: Prudhvi Raj Rekula  \n",
    "### Date: June 2025  \n",
    "### Data Source: [WA State EV Data](https://catalog.data.gov/dataset/electric-vehicle-population-data)\n",
    "\n",
    "This project explores electric vehicle (EV) adoption across Washington State using public data. The goal is to uncover trends, visualize geospatial patterns, and train a model to predict EV types based on vehicle features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d6caad",
   "metadata": {},
   "source": [
    "## üîç Key Findings\n",
    "- **Battery Electric Vehicles (BEVs)** tend to have a longer electric range but a higher MSRP.\n",
    "- **Registrations** are heavily concentrated in urban counties like King and Snohomish.\n",
    "- **Electric range** has significantly increased for models after 2017.\n",
    "- **Utility providers** like PSE and Seattle City Light have high EV coverage.\n",
    "- **Random Forest Classifier** achieved high accuracy in classifying EV type from features like make, model, MSRP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ae18e4",
   "metadata": {},
   "source": [
    "## üéØ Project Goal\n",
    "Support the **Washington State Department of Transportation** and EV infrastructure planners by analyzing trends in EV adoption and predicting EV classifications based on vehicle attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093cec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keplergl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd34b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import patsy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keplergl import KeplerGl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f35884",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAnalysis:\n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Initializes a DataAnalysis instance by loading a dataset from a file path.\n",
    "\n",
    "        Parameters:\n",
    "            file_path (str): Path to the dataset file (CSV format).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.df = pd.read_csv(file_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found at {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads the dataset from a file path and returns a pandas DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "            file_path (str): Path to the dataset file (CSV format).\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: Loaded DataFrame containing the dataset.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return pd.read_csv(file_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found at {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    def filter_data(self, column, value):\n",
    "        \"\"\"\n",
    "        Filters the DataFrame based on a column and value.\n",
    "        Returns a new DataFrame with the filtered rows.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.df[self.df[column] == value]\n",
    "        except KeyError:\n",
    "            print(f\"Error: Column '{column}' not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    def group_data(self, group_by, aggregate_func=None):\n",
    "        \"\"\"\n",
    "        Groups the DataFrame based on one or more columns.\n",
    "        Optionally applies an aggregate function to a specified column.\n",
    "        Returns a grouped DataFrame or a Series if an aggregate function is provided.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if aggregate_func is None:\n",
    "                return self.df.groupby(group_by)\n",
    "            else:\n",
    "                column, func = aggregate_func\n",
    "                return self.df.groupby(group_by)[column].agg(func)\n",
    "        except KeyError:\n",
    "            print(f\"Error: Column(s) '{group_by}' or '{column}' not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    def print_vehicle_info(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Prints vehicle information based on the provided arguments.\n",
    "        *args: Positional arguments (VIN, model, make, etc.)\n",
    "        **kwargs: Keyword arguments (verbose=True/False, show_range=True/False, electric_range=value)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            verbose = kwargs.get('verbose', False)\n",
    "            show_range = kwargs.get('show_range', False)\n",
    "            print(\"Vehicle Information:\")\n",
    "            for arg in args:\n",
    "                print(f\"- {arg}\")\n",
    "            if verbose:\n",
    "                print(\"Additional Information:\")\n",
    "                for key, value in kwargs.items():\n",
    "                    if key != 'verbose' and key != 'show_range':\n",
    "                        print(f\" {key}: {value}\")\n",
    "            if show_range:\n",
    "                electric_range = kwargs.get('electric_range', None)\n",
    "                if electric_range is not None:\n",
    "                    print(f\"Electric Range: {electric_range} miles\")\n",
    "                else:\n",
    "                    print(\"Error: Electric range not provided\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    def perform_linear_regression(self):\n",
    "        \"\"\"\n",
    "        Performs linear regression to predict Base MSRP based on Model Year and Electric Range.\n",
    "        Removes outliers and evaluates using R-squared.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from sklearn.linear_model import LinearRegression\n",
    "            from sklearn.model_selection import train_test_split\n",
    "            from sklearn.metrics import r2_score\n",
    "    \n",
    "            # Keep only numeric features\n",
    "            df_reg = self.df[['Model Year', 'Electric Range', 'Base MSRP']].dropna()\n",
    "    \n",
    "            # Remove top 1% MSRP outliers\n",
    "            q_high = df_reg['Base MSRP'].quantile(0.99)\n",
    "            df_reg = df_reg[df_reg['Base MSRP'] <= q_high]\n",
    "    \n",
    "            X = df_reg[['Model Year', 'Electric Range']]\n",
    "            y = df_reg['Base MSRP']\n",
    "    \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "    \n",
    "            r_squared = r2_score(y_test, y_pred)\n",
    "            print(f\"‚úÖ Linear Regression Completed\")\n",
    "            print(f\"R-squared score: {r_squared:.4f}\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error during linear regression: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "    def plot_histogram_for_make(self):\n",
    "        \"\"\"\n",
    "        Plots a histogram for the top 10 makes in the dataset.\n",
    "\n",
    "        This method counts the frequency of each vehicle make and plots a histogram\n",
    "        showing the distribution of the top 10 vehicle makes.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            self.df['Make'].value_counts().head(10).plot(kind='bar', color='skyblue')\n",
    "            plt.title('Histogram of Top 10 Makes')\n",
    "            plt.xlabel('Make')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.grid(axis='y')\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    def plot_pair_plot(self):\n",
    "        \"\"\"\n",
    "        Plots a pair plot for the features in the dataset.\n",
    "\n",
    "        This method creates a pair plot to visualize pairwise relationships\n",
    "        between different features in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            sns.pairplot(self.df)\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    def plot_heatmap(self):\n",
    "        \"\"\"\n",
    "        Plots a heatmap for the correlation between numerical features in the dataset.\n",
    "\n",
    "        This method calculates the correlation matrix for numerical features\n",
    "        and displays the correlation heatmap.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            numeric_df = self.df.select_dtypes(include=['number'])\n",
    "            correlation_matrix = numeric_df.corr()\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "            plt.title('Correlation Heatmap of Features')\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    def plot_scatter_plot(self):\n",
    "        \"\"\"\n",
    "        Plots a scatter plot for Model Year vs. Make.\n",
    "\n",
    "        This method creates a scatter plot to visualize the relationship\n",
    "        between model year and vehicle make.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.scatter(self.df['Model Year'], self.df['Make'])\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    def plot_vehicle_type_distribution(self):\n",
    "        \"\"\"\n",
    "        Plots a bar chart for the distribution of electric vehicles by type.\n",
    "\n",
    "        This method counts the distribution of electric vehicle types and\n",
    "        plots a bar chart to visualize the counts.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            vehicle_type_counts = self.df['Electric Vehicle Type'].value_counts()\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            vehicle_type_counts.plot(kind='bar')\n",
    "            plt.title('Distribution of Electric Vehicles by Type')\n",
    "            plt.xlabel('Vehicle Type')\n",
    "            plt.ylabel('Count')\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    def plot_model_year_distribution(self):\n",
    "        \"\"\"\n",
    "        Plots a histogram for the distribution of Model Year.\n",
    "\n",
    "        This method creates a histogram to visualize the distribution\n",
    "        of vehicle model years in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.hist(self.df['Model Year'], bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
    "            plt.title('Distribution of Model Year')\n",
    "            plt.xlabel('Model Year')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.show()\n",
    "        except KeyError:\n",
    "            print(\"Error: 'Model Year' column not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Electric Range Analysis\n",
    "    def plot_electric_range_distribution(self):\n",
    "        \"\"\"\n",
    "        Plots a histogram for the distribution of Electric Range.\n",
    "\n",
    "        This method creates a histogram to visualize the distribution of electric range values in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.hist(self.df['Electric Range'], bins=20, alpha=0.7, color='green', edgecolor='black')\n",
    "            plt.title('Distribution of Electric Range')\n",
    "            plt.xlabel('Electric Range')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.show()\n",
    "        except KeyError:\n",
    "            print(\"Error: 'Electric Range' column not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Count Analysis\n",
    "    def plot_cafv_eligibility_count(self):\n",
    "        \"\"\"\n",
    "        Plots a bar chart for the count of Clean Alternative Fuel Vehicle (CAFV) Eligibility.\n",
    "\n",
    "        This method counts the number of vehicles eligible for CAFV and plots a bar chart to show the counts.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.df['Clean Alternative Fuel Vehicle (CAFV) Eligibility'].value_counts().plot(kind='bar')\n",
    "            plt.title('Count of CAFV Eligibility')\n",
    "            plt.xlabel('CAFV Eligibility')\n",
    "            plt.ylabel('Count')\n",
    "            plt.show()\n",
    "        except KeyError:\n",
    "            print(\"Error: 'Clean Alternative Fuel Vehicle (CAFV) Eligibility' column not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Scatter Plot Analysis between Model Year and Electric Range\n",
    "    def plot_model_year_vs_electric_range(self):\n",
    "        \"\"\"\n",
    "        Plots a scatter plot for Model Year vs. Electric Range.\n",
    "\n",
    "        This method creates a scatter plot to visualize the relationship between model year and electric range.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(self.df['Model Year'], self.df['Electric Range'])\n",
    "            plt.title('Model Year vs Electric Range')\n",
    "            plt.xlabel('Model Year')\n",
    "            plt.ylabel('Electric Range')\n",
    "            plt.show()\n",
    "        except KeyError:\n",
    "            print(\"Error: 'Model Year' or 'Electric Range' column not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Vehicle analysis in top 10 counties\n",
    "    def plot_top_counties(self):\n",
    "        \"\"\"\n",
    "        Plots a bar chart for the count of vehicles by county (top 10).\n",
    "\n",
    "        This method counts the number of vehicles in each county and plots a bar chart showing the top 10 counties.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            top_counties = self.df['County'].value_counts().head(10)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            top_counties.plot(kind='bar', color='purple')\n",
    "            plt.title('Count of Vehicles by County (Top 10)')\n",
    "            plt.xlabel('County')\n",
    "            plt.ylabel('Count')\n",
    "            plt.show()\n",
    "        except KeyError:\n",
    "            print(\"Error: 'County' column not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Vehicle Analysis in top 10 cities\n",
    "    def plot_top_cities(self):\n",
    "        \"\"\"\n",
    "        Plots a bar chart for the count of vehicles by city (top 10).\n",
    "\n",
    "        This method counts the number of vehicles in each city and plots a bar chart showing the top 10 cities.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            top_cities = self.df['City'].value_counts().head(10)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            top_cities.plot(kind='bar', color='brown')\n",
    "            plt.title('Count of Vehicles by City (Top 10)')\n",
    "            plt.xlabel('City')\n",
    "            plt.ylabel('Count')\n",
    "            plt.show()\n",
    "        except KeyError:\n",
    "            print(\"Error: 'City' column not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Utility Company Analysis\n",
    "    def plot_top_utility_companies(self):\n",
    "        \"\"\"\n",
    "        Plots a bar chart for the distribution of electric vehicles by top 5 utility companies.\n",
    "\n",
    "        This method counts the distribution of electric vehicles among the top 5 utility companies and plots a bar chart.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            utility_company_counts = self.df['Electric Utility'].value_counts().head(5)\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            utility_company_counts.plot(kind='bar')\n",
    "            plt.title('Distribution of Electric Vehicles by Top 5 Utility Companies')\n",
    "            plt.xlabel('Utility Company')\n",
    "            plt.ylabel('Count')\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.show()\n",
    "        except KeyError:\n",
    "            print(\"Error: 'Electric Utility' column not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Comparision Analysis\n",
    "    def plot_bev_phev_comparison(self):\n",
    "        \"\"\"\n",
    "        Plots a comparison of Battery Electric Vehicles (BEVs) and Plug-in Hybrid Electric Vehicles (PHEVs)\n",
    "        based on Electric Range vs. MSRP (Base Manufacturer's Suggested Retail Price).\n",
    "\n",
    "        This method creates a scatter plot comparing BEVs and PHEVs based on their electric range and MSRP.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            bev_data = self.df[self.df['Electric Vehicle Type'] == 'Battery Electric Vehicle (BEV)']\n",
    "            phev_data = self.df[self.df['Electric Vehicle Type'] == 'Plug-in Hybrid Electric Vehicle (PHEV)']\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            sns.scatterplot(x='Electric Range', y='Base MSRP', data=bev_data, alpha=0.5)\n",
    "            plt.title('BEVs: Electric Range vs. MSRP')\n",
    "            plt.xlabel('Electric Range (miles)')\n",
    "            plt.ylabel('MSRP ($)')\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            sns.scatterplot(x='Electric Range', y='Base MSRP', data=phev_data, alpha=0.5)\n",
    "            plt.title('PHEVs: Electric Range vs. MSRP')\n",
    "            plt.xlabel('Electric Range (miles)')\n",
    "            plt.ylabel('MSRP ($)')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except KeyError:\n",
    "            print(\"Error: 'Electric Vehicle Type' or 'Electric Range' or 'Base MSRP' column not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Multivariate Analysis\n",
    "    def plot_multivariate_analysis(self):\n",
    "        \"\"\"\n",
    "        Optimized multivariate analysis using sample data and selected features.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            columns_to_analyze = ['Model Year', 'Electric Range', 'Base MSRP', 'Electric Vehicle Type']\n",
    "            multivariate_data = self.df[columns_to_analyze].dropna()\n",
    "    \n",
    "            # Sample 1000 rows to avoid performance issues\n",
    "            sampled_data = multivariate_data.sample(n=1000, random_state=42)\n",
    "    \n",
    "            # Plot using Electric Vehicle Type (fewer categories)\n",
    "            import seaborn as sns\n",
    "            import matplotlib.pyplot as plt\n",
    "            sns.pairplot(sampled_data, hue='Electric Vehicle Type', diag_kind='kde', corner=True)\n",
    "            plt.show()\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Merging two DataFrames\n",
    "    def merge_dataframes(self, other_file_path, on='County', how='inner'):\n",
    "        \"\"\"\n",
    "        Merges the current DataFrame with another DataFrame read from a CSV file.\n",
    "\n",
    "        This method reads another DataFrame from the specified CSV file path,\n",
    "        merges it with the current DataFrame based on the specified 'on' column and 'how' merge type,\n",
    "        and returns the merged DataFrame.\n",
    "\n",
    "        Args:\n",
    "            other_file_path (str): Path to the CSV file containing the other DataFrame.\n",
    "            on (str): Column name to merge on (default is 'County').\n",
    "            how (str): Type of merge to perform (default is 'inner').\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Merged DataFrame.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            other_df = pd.read_csv(other_file_path)\n",
    "            merged_df = pd.merge(self.df, other_df, on=on, how=how)\n",
    "            return merged_df\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found at {other_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Slicing Data of a Model Year column value (like year and filtering values depending on the categorical data)\n",
    "    def filter_by_model_year(self, model_year):\n",
    "        \"\"\"\n",
    "        Filters the DataFrame to include rows with a specific Model Year.\n",
    "\n",
    "        This method filters the DataFrame to include only rows where the 'Model Year' column matches the specified year.\n",
    "\n",
    "        Args:\n",
    "            model_year (int): The model year to filter by.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered DataFrame based on the specified Model Year.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.df[self.df['Model Year'] == model_year]\n",
    "        except KeyError:\n",
    "            print(\"Error: 'Model Year' column not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Representing data in matrix form\n",
    "    def get_data_matrix(self):\n",
    "        \"\"\"\n",
    "        Retrieves the entire DataFrame as a NumPy array.\n",
    "\n",
    "        This method returns the entire DataFrame represented as a NumPy array.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: The DataFrame converted into a NumPy array.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.df.values\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    def get_selected_data_matrix(self, selected_columns):\n",
    "        \"\"\"\n",
    "        Retrieves selected columns of the DataFrame as a NumPy array.\n",
    "\n",
    "        This method returns a subset of the DataFrame, consisting of the specified 'selected_columns',\n",
    "        represented as a NumPy array.\n",
    "\n",
    "        Args:\n",
    "            selected_columns (list): List of column names to select.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Subset of the DataFrame (selected columns) converted into a NumPy array.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            selected_data = self.df[selected_columns]\n",
    "            return selected_data.values\n",
    "        except KeyError:\n",
    "            print(f\"Error: One or more columns not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Uploading data to Numerical Python (NumPy)\n",
    "    def get_numpy_array(self):\n",
    "        \"\"\"\n",
    "        Retrieves the DataFrame as a NumPy array.\n",
    "\n",
    "        This method converts the entire DataFrame into a NumPy array.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: The DataFrame converted into a NumPy array.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return np.array(self.df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Selecting data based on a category\n",
    "    def filter_by_category(self, column, category):\n",
    "        \"\"\"\n",
    "        Filters the DataFrame based on a specific category within a column.\n",
    "\n",
    "        This method filters the DataFrame to include only rows where the specified 'column' matches the 'category'.\n",
    "\n",
    "        Args:\n",
    "            column (str): Name of the column to filter by.\n",
    "            category (str or int): Category to filter on within the specified column.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered DataFrame based on the specified category.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.df[self.df[column] == category]\n",
    "        except KeyError:\n",
    "            print(f\"Error: Column '{column}' not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Using mathematical and statistical functions using libraries\n",
    "    def create_brand_model_column(self):\n",
    "        \"\"\"\n",
    "        Creates a new column 'Brand & Model' combining 'Make' and 'Model Year' columns.\n",
    "\n",
    "        This method concatenates the 'Make' and 'Model Year' columns to create a new column 'Brand & Model'.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: The newly created 'Brand & Model' column.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.df['Brand & Model'] = self.df['Make'] + ' ' + self.df['Model Year'].astype(str)\n",
    "            return self.df['Brand & Model']\n",
    "        except KeyError:\n",
    "            print(\"Error: 'Make' or 'Model Year' column not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    def sort_by_column(self, column, ascending=False):\n",
    "        \"\"\"\n",
    "        Sorts the DataFrame based on a specified column.\n",
    "\n",
    "        This method sorts the DataFrame based on the specified 'column' in either ascending or descending order.\n",
    "\n",
    "        Args:\n",
    "            column (str): Name of the column to sort by.\n",
    "            ascending (bool, optional): Whether to sort in ascending (True) or descending (False) order.\n",
    "                                        Default is False (descending order).\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Sorted DataFrame based on the specified column and order.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.df.sort_values(by=column, ascending=ascending)\n",
    "        except KeyError:\n",
    "            print(f\"Error: Column '{column}' not found in the DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    def create_keplergl_map(self):\n",
    "        \"\"\"\n",
    "        Creates an interactive map using KeplerGl for visualizing vehicle locations.\n",
    "\n",
    "        This method extracts latitude and longitude from the 'Vehicle Location' column,\n",
    "        samples the data, and displays an interactive map using KeplerGl.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Extract latitude and longitude\n",
    "            self.df['Latitude'] = self.df['Vehicle Location'].apply(lambda x: float(x.split()[1][1:]) if isinstance(x, str) else None)\n",
    "            self.df['Longitude'] = self.df['Vehicle Location'].apply(lambda x: float(x.split()[2][:-1]) if isinstance(x, str) else None)\n",
    "\n",
    "            # Randomly sample 100000 data points\n",
    "            sampled_df = self.df.sample(n=100000, random_state=42)\n",
    "\n",
    "            # Create a Kepler.gl map\n",
    "            map_1 = KeplerGl(height=600)\n",
    "            map_1.add_data(data=sampled_df, name='vehicle_locations')\n",
    "\n",
    "            return map_1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "            return None\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        # Select relevant features and target variable\n",
    "        features = ['Model Year', 'Make', 'Model', 'Electric Range', 'Base MSRP', 'Electric Vehicle Type']\n",
    "        df_cleaned = self.df[features].dropna()  # Drop rows with any missing values\n",
    "\n",
    "        # Split features and target variable\n",
    "        X = df_cleaned.drop('Electric Vehicle Type', axis=1)\n",
    "        y = df_cleaned['Electric Vehicle Type']\n",
    "\n",
    "        # One-hot encode categorical features\n",
    "        categorical_features = ['Make', 'Model']\n",
    "        categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', categorical_transformer, categorical_features)\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "\n",
    "        # Apply preprocessing\n",
    "        X_encoded = preprocessor.fit_transform(X)\n",
    "\n",
    "        return X_encoded, y\n",
    "\n",
    "    def train_random_forest_classifier(self):\n",
    "        \"\"\"\n",
    "        Trains a Random Forest classifier with sampled, stratified, and encoded data.\n",
    "        Prevents overfitting and improves generalization.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            from sklearn.model_selection import train_test_split\n",
    "            from sklearn.preprocessing import OneHotEncoder\n",
    "            from sklearn.compose import ColumnTransformer\n",
    "            from sklearn.metrics import accuracy_score, classification_report\n",
    "    \n",
    "            # Select features and drop NAs\n",
    "            df_class = self.df[['Model Year', 'Make', 'Model', 'Electric Range', 'Base MSRP', 'Electric Vehicle Type']].dropna()\n",
    "    \n",
    "            # Sample 10,000 rows for training\n",
    "            df_sampled = df_class.sample(n=10000, random_state=42)\n",
    "    \n",
    "            # Prepare data\n",
    "            X = df_sampled.drop('Electric Vehicle Type', axis=1)\n",
    "            y = df_sampled['Electric Vehicle Type']\n",
    "    \n",
    "            # One-hot encode Make/Model\n",
    "            cat_features = ['Make', 'Model']\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)],\n",
    "                remainder='passthrough'\n",
    "            )\n",
    "            X_encoded = preprocessor.fit_transform(X)\n",
    "    \n",
    "            # Stratified split to preserve BEV/PHEV ratio\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "            # Train Random Forest\n",
    "            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            rf_model.fit(X_train, y_train)\n",
    "            y_pred = rf_model.predict(X_test)\n",
    "    \n",
    "            print(\"‚úÖ Random Forest Classification Completed\")\n",
    "            print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "            print(\"Classification Report:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error during Random Forest training: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397ba26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analysis = DataAnalysis(\"Electric_Vehicle_Population_Data.csv\")\n",
    "data = data_analysis.load_data(\"Electric_Vehicle_Population_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09423abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data\n",
    "filtered_data = data_analysis.filter_data(column='Model Year', value=2020)\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1648a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data\n",
    "filtered_data = data_analysis.filter_data(column='Model Year', value=2020)\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673dcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print vehicle info\n",
    "data_analysis.print_vehicle_info('VIN123', 'Tesla', 'Model S', verbose=True, show_range=True, electric_range=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram for make\n",
    "data_analysis.plot_histogram_for_make()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 1000 rows from your loaded data\n",
    "sampled_df = data_analysis.df.sample(n=1000, random_state=42)\n",
    "\n",
    "# Now draw the pairplot with selected columns and simpler hue\n",
    "import seaborn as sns\n",
    "cols = ['Model Year', 'Electric Range', 'Base MSRP', 'Electric Vehicle Type']\n",
    "sns.pairplot(sampled_df[cols], hue='Electric Vehicle Type', diag_kind='kde', corner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f9c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "data_analysis.plot_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter plot\n",
    "data_analysis.plot_scatter_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dba53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot vehicle type distribution\n",
    "data_analysis.plot_vehicle_type_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model year distribution\n",
    "data_analysis.plot_model_year_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106964fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot electric range distribution\n",
    "data_analysis.plot_electric_range_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bdbab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CAFV eligibility count\n",
    "data_analysis.plot_cafv_eligibility_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311cf4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model year vs electric range\n",
    "data_analysis.plot_model_year_vs_electric_range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top counties\n",
    "data_analysis.plot_top_counties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6babccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top cities\n",
    "data_analysis.plot_top_cities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f5ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top utility companies\n",
    "data_analysis.plot_top_utility_companies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b32de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot BEV vs PHEV comparison\n",
    "data_analysis.plot_bev_phev_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01693f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot multivariate analysis\n",
    "data_analysis.plot_multivariate_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d1ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by model year\n",
    "filtered_by_model_year = data_analysis.filter_by_model_year(model_year=2020)\n",
    "filtered_by_model_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54160cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data matrix\n",
    "data_matrix = data_analysis.get_data_matrix()\n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6582a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected data matrix\n",
    "selected_data_matrix = data_analysis.get_selected_data_matrix(selected_columns=['Make', 'Model Year', 'Electric Range'])\n",
    "selected_data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c06b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numpy array\n",
    "numpy_array = data_analysis.get_numpy_array()\n",
    "numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0687240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create brand model column\n",
    "brand_model_column = data_analysis.create_brand_model_column()\n",
    "brand_model_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by column\n",
    "sorted_data = data_analysis.sort_by_column(column='Model Year')\n",
    "sorted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc154d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform linear regression\n",
    "data_analysis.perform_linear_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11953132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the create_keplergl_map method using the instance\n",
    "data_analysis.create_keplergl_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeca49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Filter and sample the dataset\n",
    "df_sampled = data_analysis.df[['Model Year', 'Make', 'Electric Range', 'Electric Vehicle Type']].dropna()\n",
    "df_sampled = df_sampled.sample(n=10000, random_state=42)\n",
    "\n",
    "# Step 2: Prepare X and y\n",
    "X = df_sampled[['Model Year', 'Make', 'Electric Range']]\n",
    "y = df_sampled['Electric Vehicle Type']\n",
    "\n",
    "# Step 3: Encode categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), ['Make'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_encoded = preprocessor.fit_transform(X)\n",
    "\n",
    "# Step 4: Cross-validate the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "scores = cross_val_score(rf_model, X_encoded, y, cv=5)\n",
    "\n",
    "# Step 5: Output results\n",
    "print(\"‚úÖ Cross-validated Accuracy Scores:\", scores)\n",
    "print(\"üìä Mean Accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c792ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d108f4a",
   "metadata": {},
   "source": [
    "## üöÄ Model Comparison: Random Forest vs XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Preprocessing\n",
    "df = data_analysis.df[['Model Year', 'Make', 'Electric Range', 'Electric Vehicle Type']].dropna()\n",
    "df = df.sample(n=10000, random_state=42)\n",
    "\n",
    "X = df[['Model Year', 'Make', 'Electric Range']]\n",
    "y = df['Electric Vehicle Type']\n",
    "\n",
    "# Step 2: Encode categorical 'Make'\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), ['Make'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_encoded = preprocessor.fit_transform(X)\n",
    "\n",
    "# Step 3: Encode y labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Step 4: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Step 5: XGBoost Training\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa5763",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Electric Vehicle Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b3f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Model Year', 'Electric Range']].copy()  # make an explicit copy\n",
    "X['Electric Range'] += np.random.normal(0, 1, size=len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Filter and prepare data\n",
    "df_clean = data_analysis.df[['Model Year', 'Electric Range', 'Electric Vehicle Type']].dropna()\n",
    "df_clean = df_clean.sample(n=10000, random_state=42)\n",
    "\n",
    "X = df_clean[['Model Year', 'Electric Range']].copy()\n",
    "X['Electric Range'] += np.random.normal(0, 1, size=len(X))\n",
    "\n",
    "y = df_clean['Electric Vehicle Type']\n",
    "\n",
    "# Step 2: Encode target\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Step 3: Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 4: Cross-validation with XGBoost\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "scores = cross_val_score(xgb_model, X_scaled, y_encoded, cv=5)\n",
    "\n",
    "# Step 5: Print results\n",
    "print(\"‚úÖ Cross-validated Accuracy Scores:\", scores)\n",
    "print(\"üìä Mean Accuracy:\", np.mean(scores))\n",
    "print(\"üìâ Standard Deviation:\", np.std(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model manually\n",
    "xgb_model.fit(X_scaled, y_encoded)\n",
    "\n",
    "# Then get feature importances\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "# If you're using a preprocessor (e.g. ColumnTransformer), get feature names\n",
    "# If not, just use X.columns or a manual list\n",
    "feat_names = ['Model Year', 'Electric Range']  # or use preprocessor.get_feature_names_out() if pipeline used\n",
    "\n",
    "# Create DataFrame of importances\n",
    "feat_imp_df = pd.DataFrame({'Feature': feat_names, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(feat_imp_df['Feature'], feat_imp_df['Importance'])\n",
    "plt.title(\"XGBoost Feature Importances\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a151a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bc986ca",
   "metadata": {},
   "source": [
    "## üìâ Linear Regression on MSRP using Model Year and Electric Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predicting Base MSRP from Model Year and Electric Range\n",
    "try:\n",
    "    df_reg = data_analysis.df[['Model Year', 'Electric Range', 'Base MSRP']].dropna()\n",
    "    X = df_reg[['Model Year', 'Electric Range']]\n",
    "    y = df_reg['Base MSRP']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    print(\"‚úÖ Linear Regression Completed\")\n",
    "    print(\"R-squared score:\", r2_score(y_test, y_pred))\n",
    "except Exception as e:\n",
    "    print(\"Error during linear regression:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5df70a1",
   "metadata": {},
   "source": [
    "## üå≤ Random Forest Classifier (Improved) with Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e5770",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use a sampled and properly preprocessed dataset\n",
    "try:\n",
    "    df_class = data_analysis.df[['Model Year', 'Make', 'Model', 'Electric Range', 'Base MSRP', 'Electric Vehicle Type']].dropna()\n",
    "\n",
    "    # Sample to reduce memory and overfitting\n",
    "    df_sampled = df_class.sample(n=10000, random_state=42)\n",
    "\n",
    "    X = df_sampled.drop('Electric Vehicle Type', axis=1)\n",
    "    y = df_sampled['Electric Vehicle Type']\n",
    "\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "\n",
    "    cat_features = ['Make', 'Model']\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    X_encoded = preprocessor.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    print(\"‚úÖ Random Forest Classification Completed\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "except Exception as e:\n",
    "    print(\"Error during Random Forest training:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aef349",
   "metadata": {},
   "source": [
    "## ü§ñ Machine Learning Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ddcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Sample and clean data\n",
    "df_sampled = data_analysis.df[['Model Year', 'Make', 'Electric Range', 'Electric Vehicle Type']].dropna()\n",
    "df_sampled = df_sampled.sample(n=10000, random_state=42)\n",
    "\n",
    "X = df_sampled[['Model Year', 'Make', 'Electric Range']]\n",
    "y = df_sampled['Electric Vehicle Type']\n",
    "\n",
    "# One-hot encode 'Make'\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), ['Make'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_encoded = preprocessor.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333be71c",
   "metadata": {},
   "source": [
    "### üå≤ Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c2d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy (Random Forest):\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d338e8fa",
   "metadata": {},
   "source": [
    "### üîÅ Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f15f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy (Logistic Regression):\", accuracy_score(y_test, y_pred_log))\n",
    "print(classification_report(y_test, y_pred_log))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd3f57",
   "metadata": {},
   "source": [
    "### ‚ö° XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10723188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# Now fit the model\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test_encoded, y_pred_xgb))\n",
    "print(classification_report(y_test_encoded, y_pred_xgb, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad06a7",
   "metadata": {},
   "source": [
    "### üìä Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot confusion matrix with label fix\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_xgb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "disp.plot(cmap='Purples', ax=ax)\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=20, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Adjust layout to prevent clipping\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e30677",
   "metadata": {},
   "source": [
    "### üîç Feature Importance (Random Forest + XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Random Forest Importance\n",
    "importances_rf = rf_model.feature_importances_\n",
    "feat_imp_rf = pd.DataFrame({'Feature': feature_names, 'Importance': importances_rf})\n",
    "feat_imp_rf.sort_values(by='Importance', ascending=False).head(10).plot(\n",
    "    kind='bar', x='Feature', y='Importance', title='Random Forest - Top 10 Features', legend=False\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# XGBoost Importance\n",
    "importances_xgb = xgb_model.feature_importances_\n",
    "feat_imp_xgb = pd.DataFrame({'Feature': feature_names, 'Importance': importances_xgb})\n",
    "feat_imp_xgb.sort_values(by='Importance', ascending=False).head(10).plot(\n",
    "    kind='bar', x='Feature', y='Importance', title='XGBoost - Top 10 Features', legend=False\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f744d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6da7212",
   "metadata": {},
   "source": [
    "\n",
    "## üßÆ Model Comparison Summary\n",
    "\n",
    "| Model                 | Accuracy | Notes |\n",
    "|----------------------|----------|-------|\n",
    "| Logistic Regression  | ~98.0%   | Performs well, simple and interpretable |\n",
    "| Random Forest        | ~99.9%   | Excellent performance, handles non-linearity |\n",
    "| XGBoost              | ~99.9%   | Best in class with strong generalization |\n",
    "\n",
    "All models perform strongly due to clear separability between BEVs and PHEVs based on Electric Range and Model Year.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23350057",
   "metadata": {},
   "source": [
    "\n",
    "## üìà Executive Summary\n",
    "\n",
    "This analysis of electric vehicles (EVs) registered in Washington state reveals the following:\n",
    "\n",
    "- **BEVs** tend to have significantly higher electric range and MSRP than **PHEVs**.\n",
    "- **Vehicle adoption** is concentrated in counties like **King** and **Snohomish**, highlighting urban demand.\n",
    "- **Model years post-2017** show a notable improvement in EV range, signaling technological advancement.\n",
    "- Machine Learning models, especially **Random Forest and XGBoost**, achieved over **99% accuracy** in classifying EV types based on a small number of features.\n",
    "\n",
    "This supports strong confidence in predictive infrastructure planning and targeted EV incentives by region and vehicle type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2793aee",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ Conclusion & Recommendations\n",
    "\n",
    "- The **XGBoost classifier** demonstrated the most consistent and accurate results, making it a reliable model for deployment.\n",
    "- Based on vehicle type concentration and registration density, Washington state may prioritize:\n",
    "  - **BEV charging infrastructure** in high-density counties like **King**\n",
    "  - **Incentives or awareness campaigns** for PHEVs in underserved counties\n",
    "- This analysis can be extended by incorporating **charging station data**, **income demographics**, or **utility load forecasts** for deeper urban planning.\n",
    "\n",
    "> Overall, this project reflects strong modeling capability, feature engineering, and practical policy insights ‚Äî ideal for data-driven decision making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033742bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff0464d4",
   "metadata": {},
   "source": [
    "## üìå Conclusion & Business Implications\n",
    "- Washington shows promising EV adoption growth, especially in urban and utility-focused regions.\n",
    "- BEVs offer superior range but come at a higher upfront cost, informing policy subsidies or incentives.\n",
    "- Infrastructure planning can prioritize top utility zones and counties with growing EV density.\n",
    "\n",
    "### ‚úÖ Next Steps\n",
    "- Build a public dashboard for stakeholders.\n",
    "- Integrate real-time EV registration data for ongoing monitoring.\n",
    "- Explore clustering or unsupervised methods for regional EV behavior segmentation.\n",
    "\n",
    "---\n",
    "**Author:** Prudhvi Raj Rekula | **Role:** Data Analyst / Data Scientist Candidate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
